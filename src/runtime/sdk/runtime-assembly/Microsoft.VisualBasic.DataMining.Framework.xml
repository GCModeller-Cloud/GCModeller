<?xml version="1.0"?>
<doc>
<assembly>
<name>
Microsoft.VisualBasic.DataMining.Framework
</name>
</assembly>
<members>
<member name="T:Microsoft.VisualBasic.DataMining.My.Resources.Resources">
<summary>
  A strongly-typed resource class, for looking up localized strings, etc.
</summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.My.Resources.Resources.ResourceManager">
<summary>
  Returns the cached ResourceManager instance used by this class.
</summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.My.Resources.Resources.Culture">
<summary>
  Overrides the current thread's CurrentUICulture property for all
  resource lookups using this strongly typed resource class.
</summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.BinaryEncodingServices.EncodingTransaction(System.String[])">
 <summary>
 ±àÂëÒ»¸öÊÂÎñ
 </summary>
 <param name="transaction"></param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.BinaryEncodingServices.DecodesTransaction(System.String)">
 <summary>
 ½âÂëÒ»¸öÊÂÎñ
 </summary>
 <param name="Transaction"></param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.EncodingServices">
 <summary>
 ½«ÊÂ¼þ½øÐÐ±àÂëÎªµ¥¸ö×Ö·û
 </summary>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.EncodingServices.#ctor(System.String[],System.Int32[])">
 <summary>
 ±àÂëÔ­Àí£¬Õâ¸öº¯ÊýÊÇÎª¶àÖµ½øÐÐ±àÂëµÄ£¬¼´<paramref name="items"></paramref>Ö®ÖÐµÄÃ¿Ò»¸öÔªËØÎªÈÎÒâÊµÊý½øÐÐÕ¹¿ª£¬È»ºó¶ÔÕ¹¿ªµÄÊý¾Ý½øÐÐ±àÂë´¦Àí
 </summary>
 <param name="Items">Value²¿·ÖÎªËùÓÐ¿ÉÄÜµÄÈ¡Öµ£¬Çë×¢Òâ£¬ValueÖ®ÖÐ²»ÄÜ¹»ÓÐÖØ¸´Öµ</param>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.EncodingServices.MapRecovered(System.String)">
 <summary>
 ÔÚ½øÐÐ¹ØÁª·ÖÎöÍê±ÏÖ®ºó£¬ÔÙÓ³Éä»ØÈ¥
 </summary>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.EncodingServices.TransactionEncoding(System.Collections.Generic.IEnumerable{Microsoft.VisualBasic.DataMining.AprioriAlgorithm.Transaction})">
 <summary>
 
 </summary>
 <param name="data">Õâ¸öµÄË³ÐòÓëÊýÄ¿±ØÐëÒªÓë<see cref="F:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.EncodingServices._CodeMappings"></see>»òÕß<see cref="F:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.EncodingServices._originals"></see>ÏàÒ»ÖÂ</param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.Transaction.Values">
 <summary>
 Õâ¸öµÄË³ÐòÓëÊýÄ¿±ØÐëÒªÓë<see cref="P:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.EncodingServices.CodeMappings"></see>»òÕß<see cref="F:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.EncodingServices._originals"></see>ÏàÒ»ÖÂ
 </summary>
 <value></value>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.Entities.Rule">
 <summary>
 
 </summary>
 <remarks></remarks>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.Entities.Rule.Confidence">
 <summary>
 
 </summary>
 <value></value>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.Apriori">
 <summary>
 
 </summary>
 <remarks></remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.AprioriAlgorithm.Apriori.SorterSortTokens(System.String)">
 <summary>
 ���ַ���֮�е��ַ������������
 </summary>
 <param name="token"></param>
 <returns></returns>
 <remarks></remarks>
 
</member>
<member name="T:Microsoft.VisualBasic.DataMining.Darwinism.DifferentialEvolution">
 <summary>
 In evolutionary computation, differential evolution (DE) is a method that optimizes a problem by 
 iteratively trying to improve a candidate solution with regard to a given measure of quality. 
 Such methods are commonly known as metaheuristics as they make few or no assumptions about the 
 problem being optimized and can search very large spaces of candidate solutions. However, 
 metaheuristics such as DE do not guarantee an optimal solution is ever found.
 
 DE Is used For multidimensional real-valued functions but does Not use the gradient Of the problem 
 being optimized, which means DE does Not require For the optimization problem To be differentiable 
 As Is required by classic optimization methods such As gradient descent And quasi-newton methods. 
 DE can therefore also be used On optimization problems that are Not even continuous, are noisy, 
 change over time, etc.[1]
 
 DE optimizes a problem by maintaining a population Of candidate solutions And creating New candidate 
 solutions by combining existing ones according To its simple formulae, And Then keeping whichever 
 candidate solution has the best score Or fitness On the optimization problem at hand. In this way 
 the optimization problem Is treated As a black box that merely provides a measure Of quality given 
 a candidate solution And the gradient Is therefore Not needed.
 
 DE Is originally due To Storn And Price.[2][3] Books have been published On theoretical And practical 
 aspects Of Using DE In parallel computing, multiobjective optimization, constrained optimization, 
 And the books also contain surveys of application areas.[4][5][6][7] Excellent surveys on the 
 multi-faceted research aspects of DE can be found in journal articles Like.[8][9]
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.DifferentialEvolution.GetPopulation``1(Microsoft.VisualBasic.DataMining.Darwinism.DifferentialEvolution.New{``0},System.Int32,Microsoft.VisualBasic.Mathematical.IRandomSeeds)">
 <summary>
 Initialize population with individuals that have been initialized with uniform random noise
 uniform noise means random value inside your search space
 </summary>
 <param name="__new"></param>
 <param name="PopulationSize%"></param>
 <returns></returns>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.DifferentialEvolution.Evolution``1(System.Func{``0,System.Double},Microsoft.VisualBasic.DataMining.Darwinism.DifferentialEvolution.New{``0},System.Int32,System.Double,System.Double,System.Double,System.Int32,System.Int32,System.Action{Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.ListenerHelper.outPrint},System.Boolean,Microsoft.VisualBasic.Mathematical.IRandomSeeds)">
 <summary>
 
 </summary>
 <typeparam name="Individual"></typeparam>
 <param name="target"></param>
 <param name="[new]">How to creates a new <typeparamref name="Individual"/></param>
 <param name="N%">dimensionality of problem, means how many variables problem has.</param>
 <param name="threshold#"></param>
 <param name="maxIterations%"></param>
 <param name="F">differential weight [0,2]</param>
 <param name="CR">crossover probability [0,1]</param>
 <param name="PopulationSize%"></param>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.DifferentialEvolution.__subPopulationEvolute``1(``0[],System.Double,System.Int32,System.Double,System.Double,System.Int32,System.Action{Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.ListenerHelper.outPrint},System.Func{``0,System.Double},Microsoft.VisualBasic.Mathematical.IRandomSeeds)">
 <summary>
 
 </summary>
 <typeparam name="Individual"></typeparam>
 <param name="population"></param>
 <param name="F#"></param>
 <param name="N%"></param>
 <param name="CR#"></param>
 <param name="bestFit#"></param>
 <param name="iterates%">i</param>
 <param name="iteratePrints"></param>
 <param name="fitnessFunction"></param>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.Models.FitnessPool`2.Fitness(`0)">
 <summary>
 This function tells how well given individual performs at given problem.
 </summary>
 <param name="[in]"></param>
 <returns></returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.Darwinism.Models.Chromosome`1">
 <summary>
 In computer programming, genetic representation is a way of representing 
 solutions/individuals in evolutionary computation methods. Genetic 
 representation can encode appearance, behavior, physical qualities of 
 individuals. Designing a good genetic representation that is expressive 
 and evolvable is a hard problem in evolutionary computation. Difference 
 in genetic representations is one of the major criteria drawing a line 
 between known classes of evolutionary computation.

 Terminology often comes by analogy With natural genetics. The block Of 
 computer memory that represents one candidate solution Is called an individual. 
 The data In that block Is called a chromosome. Each chromosome consists Of 
 genes. The possible values Of a particular gene are called alleles. A 
 programmer may represent all the individuals Of a population Using binary 
 encoding, permutational encoding, encoding by tree, Or any one Of several 
 other representations.

 Genetic algorithms use linear binary representations. The most standard one 
 Is an array Of bits. Arrays Of other types And structures can be used In 
 essentially the same way. The main Property that makes these genetic 
 representations convenient Is that their parts are easily aligned due To 
 their fixed size. This facilitates simple crossover operation. Variable 
 length representations were also explored In Genetic algorithms, but crossover 
 implementation Is more complex In this Case.

 Evolution strategy uses linear real-valued representations, e.g. an array 
 Of real values. It uses mostly gaussian mutation And blending/averaging 
 crossover.

 Genetic programming(GP) pioneered tree-Like representations And developed 
 genetic operators suitable For such representations. Tree-Like representations 
 are used In GP To represent And evolve functional programs With desired 
 properties.

 Human-based genetic algorithm (HBGA) offers a way to avoid solving hard 
 representation problems by outsourcing all genetic operators to outside 
 agents, in this case, humans. The algorithm has no need for knowledge 
 of a particular fixed genetic representation as long as there are enough 
 external agents capable of handling those representations, allowing for 
 free-form And evolving genetic representations.
 </summary>
 <typeparam name="C"></typeparam>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.Models.Chromosome`1.Crossover(`0)">
 <summary>
 In genetic algorithms, crossover is a genetic operator used to vary the programming 
 of a chromosome or chromosomes from one generation to the next. It is analogous to 
 reproduction and biological crossover, upon which genetic algorithms are based. 
 Cross over is a process of taking more than one parent solutions and producing a 
 child solution from them. There are methods for selection of the chromosomes.
 </summary>
 <param name="anotherChromosome"></param>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.Models.Chromosome`1.Mutate">
 <summary>
 Mutation is a genetic operator used to maintain genetic diversity from one generation 
 of a population of genetic algorithm chromosomes to the next. It is analogous to 
 biological mutation. Mutation alters one or more gene values in a chromosome from its 
 initial state. In mutation, the solution may change entirely from the previous solution. 
 Hence GA can come to better solution by using mutation. Mutation occurs during evolution 
 according to a user-definable mutation probability. This probability should be set low. 
 If it is set too high, the search will turn into a primitive random search.

 The classic example Of a mutation Operator involves a probability that an arbitrary bit 
 In a genetic sequence will be changed from its original state. A common method Of 
 implementing the mutation Operator involves generating a random variable For Each bit 
 In a sequence. This random variable tells whether Or Not a particular bit will be modified. 
 This mutation procedure, based On the biological point mutation, Is called Single point 
 mutation. Other types are inversion And floating point mutation. When the gene encoding 
 Is restrictive As In permutation problems, mutations are swaps, inversions, And scrambles.

 The purpose Of mutation In GAs Is preserving And introducing diversity. Mutation should 
 allow the algorithm To avoid local minima by preventing the population Of chromosomes 
 from becoming too similar To Each other, thus slowing Or even stopping evolution. This 
 reasoning also explains the fact that most GA systems avoid only taking the fittest Of 
 the population In generating the Next but rather a random (Or semi-random) selection 
 With a weighting toward those that are fitter.
 </summary>
 <returns></returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.ChromosomesComparator`2">
 <summary>
 缓存的Key是染色体的ToString的计算值
 </summary>
 <typeparam name="C"></typeparam>
 <typeparam name="T"></typeparam>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.ListenerHelper.AddDefaultListener``1(Microsoft.VisualBasic.DataMining.Darwinism.GAF.GeneticAlgorithm{``0,System.Double}@,System.Action{Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.ListenerHelper.outPrint},System.Double)">
 <summary>
 After each iteration Genetic algorithm notifies listener
 </summary>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.FitnessHelper.Calculate(System.Double[],System.Double[])">
 <summary>
 Implements Fitness(Of C, T).Calculate
 </summary>
 <param name="chromosome#"></param>
 <param name="target#"></param>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.GeneticHelper.Mutate(System.Double[]@,System.Random)">
 <summary>
 Returns clone of current chromosome, which is mutated a bit
 </summary>
 <param name="v#"></param>
 <param name="random"></param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.GeneticHelper.Mutate(System.Int32[]@,System.Random)">
 <summary>
 Returns clone of current chromosome, which is mutated a bit
 </summary>
 <param name="v%"></param>
 <param name="random"></param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.GeneticHelper.Crossover``1(System.Random,``0[]@,``0[]@)">
 <summary>
 Returns list of siblings 
 Siblings are actually new chromosomes, 
 created using any of crossover strategy
 </summary>
 <param name="random"></param>
 <param name="v1#"></param>
 <param name="v2#"></param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.GeneticHelper.InitialPopulation``1(``0,System.Int32)">
 <summary>
 The simplest strategy for creating initial population <br/>
 in real life it could be more complex
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Fitness`2.Calculate(`0)">
 <summary>
 Assume that chromosome1 is better than chromosome2 <br/>
 fit1 = calculate(chromosome1) <br/>
 fit2 = calculate(chromosome2) <br/>
 So the following condition must be true <br/>
 fit1.compareTo(fit2) &lt;= 0 <br/>
 (假若是并行模式的之下，还要求这个函数是线程安全的)
 </summary>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.Darwinism.GAF.GeneticAlgorithm`2.iterationListeners">
 <summary>
 listeners of genetic algorithm iterations (handle callback afterwards)
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.GeneticAlgorithm`2.__iterate(System.Int32)">
 <summary>
 并行化过程之中的单个迭代
 </summary>
 <param name="i%"></param>
 <returns></returns>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.Darwinism.GAF.GeneticAlgorithm`2.ParentChromosomesSurviveCount">
 <summary>
 Number of parental chromosomes, which survive (and move to new
 population)
 </summary>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.GeneticAlgorithm`2.Clear">
 <summary>
 Clear the internal cache
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Population`1.Parallel">
 <summary>
 是否使用并行模式在排序之前来计算出fitness
 </summary>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Population`1.Add(`0)">
 <summary>
 Add chromosome
 </summary>
 <param name="chromosome"></param>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Population`1.Size">
 <summary>
 The number of chromosome elements in the inner list
 </summary>
 <returns></returns>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Population`1.Random(System.Random)">
 <summary>
 Gets random chromosome
 </summary>
 <returns></returns>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Population`1.Item(System.Int32)">
 <summary>
 Gets chromosome by index
 </summary>
 <param name="index%"></param>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Population`1.SortPopulationByFitness``1(Microsoft.VisualBasic.DataMining.Darwinism.GAF.GeneticAlgorithm{`0,``0},Microsoft.VisualBasic.DataMining.Darwinism.GAF.Helper.ChromosomesComparator{`0,``0})">
 <summary>
 这里是ODEs参数估计的限速步骤
 </summary>
 <typeparam name="T"></typeparam>
 <param name="GA"></param>
 <param name="comparator"></param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Darwinism.GAF.Population`1.Trim(System.Int32)">
 <summary>
 shortening population till specific number
 </summary>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.TFftAlgorithm">
 <summary>
 Quick Fourier Transformation. 
 Some ideas to make the Discrete Fourier Transformation a bit quicker and implemented a lean version of the DFT algorithm.
 </summary>
 <remarks>
 http://www.codeproject.com/Articles/590638/Quick-Fourier-Transformation
 
 离散傅里叶变换(discrete Fourier transform) 傅里叶分析方法是信号分析的最基本方法，傅里叶变换是傅里叶分析的核心，
 通过它把信号从时间域变换到频率域，进而研究信号的频谱结构和变化规律。
 在形式上，变换两端（时域和频域上）的序列是有限长的，而实际上这两组序列都应当被认为是离散周期信号的主值序列。
 即使对有限长的离散信号作DFT，也应当将其看作其周期延拓的变换。在实际应用中通常采用快速傅里叶变换计算DFT。
 
 下面给出离散傅里叶变换的变换对： 对于N点序列，它的离散傅里叶变换（DFT）为 其中是自然对数的底数，是虚数单位单位。
 通常以符号表示这一变换，即 离散傅里叶变换的逆变换（IDFT）为： 可以记为： 实际上，DFT和IDFT变换式中和式前面的
 归一化系数并不重要。有时会将这两个系数都改成。
 
 
 
 The FFT produce frequency samples (or spectral bin). A frequency sample is a complex number with real and imaginary part. 
 The imaginary part give the phase and the real part give the amplitude. We have to compute the magnitude in dB from this 
 to produce a nice spectrogram. The magnitude of a spectral bin is simply the amount of energy for the corresponding 
 frequency.
 (FFT产生对波形的频率的采样，一个频率采样是一个复数集合，虚数部分记录了相位，实数部分则记录了振幅。我们必须计算声贝的大小从而产生一个比较不错的分析数据)
 </remarks>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.TFftAlgorithm.a">
 <summary>
 The real value is the cosinus part
 </summary>
 <remarks>
 Compute magnitudes
 
 Now we can compute the magnitude from complex values. This is done with the good old Pythagorean theorem. 
 Each complex number can be represented in a two-dimensional space. 
 
 The real part is a, and the imaginary part is b.
 
 Magnitudes are stored in a two dimentional array magnitudes[x,y] where x is the nth FFT performed by 
 SampleTagger and y is the nth magnitude in range [0,fft_size/2]
 </remarks>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.TFftAlgorithm.b">
 <summary>
 The imag value is the sinus part
 </summary>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.TFftAlgorithm.#ctor(System.Int32)">
 <summary>
 使用本构造函数所创建的FFT对象，需要在后续的代码之中手动设置<see cref="F:Microsoft.VisualBasic.DataMining.TFftAlgorithm.y"></see>的值
 </summary>
 <param name="order"><see cref="F:Microsoft.VisualBasic.DataMining.TFftAlgorithm.y"></see>的值的数目</param>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.TFftAlgorithm.FourierTransformation">
 <summary>
 Fourier transformation calculation of the Fourier components
 </summary>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.TFftAlgorithm.InvDFT">
 <summary>
 invers Fourier transformation, rebuild the signal in real numbers
 </summary>
 <remarks></remarks>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.Clustering.SimpleCluster.offset">
 <summary>
 1 - 右偏移，即<see cref="P:Microsoft.VisualBasic.DataMining.Clustering.SimpleCluster.Items"></see>里面的对象大部分都大于<see cref="P:Microsoft.VisualBasic.DataMining.Clustering.SimpleCluster.Kernel"></see>
 0 - 不偏移，则比较有可能为一个核
 -1 - 左偏移，即大部分对象都小于<see cref="P:Microsoft.VisualBasic.DataMining.Clustering.SimpleCluster.Kernel"></see>
 </summary>
 <value></value>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Clustering.SimpleCluster.Split">
 <summary>
 核分裂
 </summary>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Clustering.Clustering.Clustering(System.Collections.Generic.IEnumerable{System.Double},System.Double)">
 <summary>
 
 </summary>
 <param name="data"></param>
 <param name="d">点之间的间距大小，当小于这个距离的任意两个点都会被划分为一个分类</param>
 <returns></returns>
 <remarks></remarks>
 
</member>
<member name="T:Microsoft.VisualBasic.DataMining.DynamicProgramming.LCS_Length">
 <summary>
 Longest Common Subsequence
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.DynamicProgramming.LCS_Length.MaxLengthSubString(System.String,System.String)">
 <summary>
 比较两个字符串之间的最长的子串
 </summary>
 <param name="a"></param>
 <param name="b"></param>
 <returns></returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.FourierTransform">
 <summary>
 Fourier transformation.
 </summary>
 
 <remarks>The class implements one dimensional and two dimensional
 Discrete and Fast Fourier Transformation.</remarks>
 
</member>
<member name="T:Microsoft.VisualBasic.DataMining.FourierTransform.Direction">
 <summary>
 Fourier transformation direction.
 </summary>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.FourierTransform.Direction.Forward">
 <summary>
 Forward direction of Fourier transformation.
 </summary>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.FourierTransform.Direction.Backward">
 <summary>
 Backward direction of Fourier transformation.
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.FourierTransform.DFT(System.Numerics.Complex[],Microsoft.VisualBasic.DataMining.FourierTransform.Direction)">
 <summary>
 One dimensional Discrete Fourier Transform.
 </summary>
 
 <param name="data">Data to transform.</param>
 <param name="direction__1">Transformation direction.</param>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.FourierTransform.DFT2(System.Numerics.Complex[0:,0:],Microsoft.VisualBasic.DataMining.FourierTransform.Direction)">
 <summary>
 Two dimensional Discrete Fourier Transform.
 </summary>
 
 <param name="data">Data to transform.</param>
 <param name="direction__1">Transformation direction.</param>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.FourierTransform.FFT(System.Numerics.Complex[],Microsoft.VisualBasic.DataMining.FourierTransform.Direction)">
 <summary>
 One dimensional Fast Fourier Transform.
 </summary>
 
 <param name="data">Data to transform.</param>
 <param name="direction__1">Transformation direction.</param>
 
 <remarks><para><note>The method accepts <paramref name="data"/> array of 2<sup>n</sup> size
 only, where <b>n</b> may vary in the [1, 14] range.</note></para></remarks>
 
 <exception cref="T:System.ArgumentException">Incorrect data length.</exception>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.FourierTransform.FFT2(System.Numerics.Complex[0:,0:],Microsoft.VisualBasic.DataMining.FourierTransform.Direction)">
 <summary>
 Two dimensional Fast Fourier Transform.
 </summary>
 
 <param name="data">Data to transform.</param>
 <param name="direction">Transformation direction.</param>
 
 <remarks><para><note>The method accepts <paramref name="data"/> array of 2<sup>n</sup> size
 only in each dimension, where <b>n</b> may vary in the [1, 14] range. For example, 16x16 array
 is valid, but 15x15 is not.</note></para></remarks>
 
 <exception cref="T:System.ArgumentException">Incorrect data length.</exception>
 
</member>
<member name="T:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement">
 <summary>
 This object represents the factor which decides the node state changes.(决定<see cref="T:Microsoft.VisualBasic.DataMining.DFL_Driver.dflNode"></see>的状态的因素)
 </summary>
 <remarks></remarks>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement._Weight">
 <summary>
 <see cref="F:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement._Weight"></see>越大,则<see cref="F:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement._ABS_Weight"></see>越小，即事件发生的阈值越小
 </summary>
 <remarks></remarks>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement._ABS_Weight">
 <summary>
  1 - <see cref="M:System.Math.Abs(System.Decimal)"></see>(<see cref="F:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement._Weight"></see>)
 </summary>
 <remarks></remarks>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement.Weight">
 <summary>
 Weight = [-1,1]. (可以带有符号，介于-1到1之间)
 </summary>
 <value></value>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement.FunctionalState">
 <summary>
 Does this factor effects on the node states changes? value zero is no effects.
 (当前的这个因素是否会影响目标节点的状态值的改变，0表示不影响)
 </summary>
 <value></value>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement.Internal_getEventProbabilities">
 <summary>
 计算公式为 (1-w)， 即本函数返回的值越低，则事件越容易发生，请注意使用 rnd >= Internal_getEventProbabilities() 来描述事件发生
 </summary>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement.get_InteractionQuantity">
 <summary>
 假若事件发生的话，这个函数决定了<see cref="P:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement.FunctionalState"></see>所返回的计算值
 </summary>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement.ShadowCopy(Microsoft.VisualBasic.DataMining.DFL_Driver.I_FactorElement,Microsoft.VisualBasic.DataMining.DFL_Driver.dflNode)">
 <summary>
 <see cref="T:Microsoft.VisualBasic.DataMining.DFL_Driver.dflNode"></see>对象初始化的时候所使用的方法
 </summary>
 <param name="data"></param>
 <param name="Target"></param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.DFL_Driver.dflNode">
 <summary>
 A node in the fuzzy logic network.(模糊逻辑网络之中的一个节点)
 </summary>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.DFL_Driver.dflNode.get_FactorsCollectionWeight">
 <summary>
 获取当前节点上面的调控因子的数量的总和
 </summary>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.KMeans.EntityLDM">
 <summary>
 存储在Csv文件里面的数据模型
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.Extensions.ValueGroups(System.Collections.Generic.IEnumerable{System.Double},System.Int32)">
 <summary>
 Grouping the numeric values by using the kmeans cluserting operations.
 (对一组数字进行聚类操作，其实在这里就是将这组数值生成Entity数据对象，然后将数值本身作为自动生成的Entity对象的一个唯一属性)
 </summary>
 <param name="array"></param>
 <param name="nd"></param>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.Extensions.Kmeans(System.Collections.Generic.IEnumerable{Microsoft.VisualBasic.DataMining.KMeans.EntityLDM},System.Int32,System.Boolean,System.Boolean)">
 <summary>
 Performance the clustering operation on the entity data model.
 </summary>
 <param name="source"></param>
 <param name="n"></param>
 <returns></returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.KMeans.CompleteLinkage.Clustering">
 <summary>
 
 </summary>
 <remarks>
 https://github.com/halfjew22/Clustering/blob/master/src/com/lustig/model/Clustering.java
 </remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.KMeans.Entity">
 <summary>
 计算所使用的对象实例实体模型
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.Entity.Load(System.String,System.String)">
 <summary>

 </summary>
 <param name="path">Csv文件之中除了第一列是名称标识符，其他的都必须是该实体对象的属性</param>
 <returns></returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.KMeans.KMeansCluster`1">
 <summary>
 A class containing a group of data with similar characteristics (cluster), KMeans Cluster
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.KMeans.KMeansCluster`1.ClusterSum">
 <summary>
 The sum of all the data in the cluster
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.KMeans.KMeansCluster`1.ClusterMean">
 <summary>
 The mean of all the data in the cluster
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.KMeansCluster`1.Add(`0)">
 <summary>
 Adds a single dimension array data to the cluster.
 (请注意，每当使用这个方法新添加一个对象的时候，都会导致均值被重新计算)
 </summary>
 <param name="data">A 1-dimensional array containing data that will be added to the cluster</param>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.KMeans.KMeansCluster`1.Item(System.Int32)">
 <summary>
 Returns the one dimensional array data located at the index
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.KMeansCluster`1.refresh">
 <summary>
 Will keep the center member variable, but clear the list of points
 within the cluster.
 </summary>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.KMeans.ClusterCollection`1">
 <summary>
 A collection of Cluster objects or Clusters
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.ClusterCollection`1.Add(Microsoft.VisualBasic.DataMining.KMeans.KMeansCluster{`0})">
 <summary>
 Adds a Cluster to the collection of Clusters
 </summary>
 <param name="cluster">A Cluster to be added to the collection of clusters</param>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.KMeans.ClusterCollection`1.Item(System.Int32)">
 <summary>
 Returns the Cluster at this index
 </summary>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.KMeans.KMeansAlgorithm">
 <summary>
 This class implement a KMeans clustering algorithm.(请注意，实体对象的属性必须要长度一致)
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.KMeansAlgorithm.EuclideanDistance(System.Double[],System.Double[])">
 <summary>
 Calculates the Euclidean Distance Measure between two data points
 </summary>
 <param name="X">An array with the values of an object or datapoint</param>
 <param name="Y">An array with the values of an object or datapoint</param>
 <returns>Returns the Euclidean Distance Measure Between Points X and Points Y</returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.KMeansAlgorithm.ManhattanDistance(System.Double[],System.Double[])">
 <summary>
 Calculates the Manhattan Distance Measure between two data points
 </summary>
 <param name="X">An array with the values of an object or datapoint</param>
 <param name="Y">An array with the values of an object or datapoint</param>
 <returns>Returns the Manhattan Distance Measure Between Points X and Points Y</returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.KMeansAlgorithm.ClusterMean(System.Double[0:,0:])">
 <summary>
 Calculates The Mean Of A Cluster OR The Cluster Center
 </summary>
 <param name="cluster">
 A two-dimensional array containing a dataset of numeric values
 </param>
 <returns>
 Returns an Array Defining A Data Point Representing The Cluster Mean or Centroid
 </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.KMeansAlgorithm.ClusterDataSet``1(System.Int32,System.Collections.Generic.IEnumerable{``0},System.Boolean,System.Int32,System.Boolean)">
 <summary>
 Seperates a dataset into clusters or groups with similar characteristics
 </summary>
 <param name="clusterCount">The number of clusters or groups to form</param>
 <param name="source">
 An array containing data that will be clustered, the elements number must greater than 2, at least 3 elements.
 (里面的元素至少需要三个)
 </param>
 <returns>A collection of clusters of data</returns>
 <param name="parallel">
 默认是使用并行化的计算代码以通过牺牲内存空间的代价来获取高性能的计算，非并行化的代码比较适合低内存的设备上面运行
 </param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.KMeansAlgorithm.ClusterDataSet``1(Microsoft.VisualBasic.DataMining.KMeans.ClusterCollection{``0},``0[],System.Boolean)">
 <summary>
 Seperates a dataset into clusters or groups with similar characteristics
 </summary>
 <param name="clusters">A collection of data clusters</param>
 <param name="data">An array containing data to be clustered</param>
 <param name="parallel">是否采用并行算法</param>
 <returns>A collection of clusters of data</returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.KMeans.KMeansAlgorithm.ToFloatMatrix(System.Data.DataTable)">
 <summary>
 Converts a System.Data.DataTable to a 2-dimensional array
 </summary>
 <param name="table">A System.Data.DataTable containing data to cluster</param>
 <returns>A 2-dimensional array containing data to cluster</returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.MarginalLikelihoodAnalysis">
 <summary>
 @author Marc Suchard
 @author Alexei Drummond
 
 Source translated from ``model_P.c`` (a component of BAli-Phy by Benjamin Redelings and Marc Suchard
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.MarginalLikelihoodAnalysis.#ctor(System.Collections.Generic.IList{System.Double},System.Int32,System.String,System.Int32)">
 <summary>
 Constructor
 </summary>
 <param name="sample"> </param>
 <param name="burnin">          used for 'toString' display purposes only </param>
 <param name="analysisType"> </param>
 <param name="bootstrapLength"> a value of zero will turn off bootstrapping </param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.MarginalLikelihoodAnalysis.logMarginalLikelihoodArithmetic(System.Collections.Generic.IList{System.Nullable{System.Double}})">
 <summary>
 Calculates the log marginal likelihood of a model using the arithmetic mean estimator
 </summary>
 <param name="v"> a posterior sample of logLikelihoods </param>
 <returns> the log marginal likelihood </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.MarginalLikelihoodAnalysis.logMarginalLikelihoodHarmonic(System.Collections.Generic.IList{System.Double})">
 <summary>
 Calculates the log marginal likelihood of a model using Newton and Raftery's harmonic mean estimator
 </summary>
 <param name="v"> a posterior sample of logLikelihoods </param>
 <returns> the log marginal likelihood </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.MarginalLikelihoodAnalysis.logMarginalLikelihoodAICM(System.Collections.Generic.IList{System.Double})">
 <summary>
 Calculates the AICM of a model using method-of-moments from Raftery et al. (2007)
 </summary>
 <param name="v"> a posterior sample of logLikelihoods </param>
 <returns> the AICM (lower values are better) </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.MarginalLikelihoodAnalysis.logMarginalLikelihoodSmoothed(System.Collections.Generic.IList{System.Double},System.Double,System.Double)">
 <summary>
 Calculates the log marginal likelihood of a model using Newton and Raftery's smoothed estimator
 </summary>
 <param name="v">     a posterior sample of logLikelihood </param>
 <param name="delta"> proportion of pseudo-samples from the prior </param>
 <param name="Pdata"> current estimate of the log marginal likelihood </param>
 <returns> the log marginal likelihood </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Abundance.RelativeAbundances``1(System.Collections.Generic.IEnumerable{``0})">
 <summary>
 x除以最大的值就是相对丰度
 </summary>
 <typeparam name="T"></typeparam>
 <param name="source"></param>
 <returns></returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.TrainingUtils">
 <summary>
 Tools for training the neuron network
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.TrainingUtils.Corrects(System.Double[],System.Double[],System.Double[],System.Boolean)">
 <summary>
 
 </summary>
 <param name="input">The inputs data</param>
 <param name="convertedResults">The error outputs</param>
 <param name="expectedResults">The corrects output</param>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.DataSet">
 <summary>
 The training dataset
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.NeuralNetwork.DataSet.Values">
 <summary>
 Neuron network input parameters
 </summary>
 <returns></returns>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.NeuralNetwork.DataSet.Targets">
 <summary>
 The network expected output values
 </summary>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.DataSet.#ctor(System.Double[],System.Double[])">
 <summary>
 
 </summary>
 <param name="values__1">Neuron network input parameters</param>
 <param name="targets__2">The network expected output values</param>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.NeuralNetwork.TrainingType.Epoch">
 <summary>
 <see cref="F:Microsoft.VisualBasic.DataMining.NeuralNetwork.Helpers.MaxEpochs"/>
 </summary>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.NeuralNetwork.TrainingType.MinimumError">
 <summary>
 <see cref="F:Microsoft.VisualBasic.DataMining.NeuralNetwork.Helpers.MinimumError"/>
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.Encoder`1.Decode(System.Double)">
 <summary>
 
 </summary>
 <param name="out">神经网络的输出值</param>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.Network.#ctor(System.Int32,System.Int32,System.Int32,System.Double,System.Double,Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.IActivationFunction)">
 <summary>
 
 </summary>
 <param name="inputSize">>=2</param>
 <param name="hiddenSize">>=2</param>
 <param name="outputSize">>=1</param>
 <param name="learnRate__1"></param>
 <param name="momentum__2"></param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.Network.Compute(System.Double[])">
 <summary>
 Compute result output for the neuron network <paramref name="inputs"/>.
 (请注意ANN的输出值是在0-1之间的，所以还需要进行额外的编码和解码)
 </summary>
 <param name="inputs"></param>
 <returns></returns>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.NeuralNetwork.Neuron.IFunc">
 <summary>
 The active function
 </summary>
 <returns></returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction">
 <summary>
 Bipolar sigmoid activation function.
 </summary>

 <remarks><para>The class represents bipolar sigmoid activation function with
 the next expression:
 <code lang="none">
                2
 f(x) = ------------------ - 1
        1 + exp(-alpha * x)

           2 * alpha * exp(-alpha * x )
 f'(x) = -------------------------------- = alpha * (1 - f(x)^2) / 2
           (1 + exp(-alpha * x))^2
 </code>
 </para>
 
 <para>Output range of the function: <b>[-1, 1]</b>.</para>
 
 <para>Functions graph:</para>
 <img src="img/neuro/sigmoid_bipolar.bmp" width="242" height="172" />
 </remarks>
 
</member>
<member name="P:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction.Alpha">
 <summary>
 Sigmoid's alpha value.
 </summary>

 <remarks><para>The value determines steepness of the function. Increasing value of
 this property changes sigmoid to look more like a threshold function. Decreasing
 value of this property makes sigmoid to be very smooth (slowly growing from its
 minimum value to its maximum value).</para>

 <para>Default value is set to <b>2</b>.</para>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction.#ctor">
 <summary>
 Initializes a new instance of the <see cref="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction"/> class.
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction.#ctor(System.Double)">
 <summary>
 Initializes a new instance of the <see cref="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction"/> class.
 </summary>
 
 <param name="alpha">Sigmoid's alpha value.</param>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction.Function(System.Double)">
 <summary>
 Calculates function value.
 </summary>

 <param name="x">Function input value.</param>
 
 <returns>Function output value, <i>f(x)</i>.</returns>

 <remarks>The method calculates function value at point <paramref name="x"/>.</remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction.Derivative(System.Double)">
 <summary>
 Calculates function derivative.
 </summary>
 
 <param name="x">Function input value.</param>
 
 <returns>Function derivative, <i>f'(x)</i>.</returns>
 
 <remarks>The method calculates function derivative at point <paramref name="x"/>.</remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction.Derivative2(System.Double)">
 <summary>
 Calculates function derivative.
 </summary>
 
 <param name="y">Function output value - the value, which was obtained
 with the help of "Function" method.</param>
 
 <returns>Function derivative, <i>f'(x)</i>.</returns>

 <remarks><para>The method calculates the same derivative value as the
 <see cref="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction.Derivative(System.Double)"/> method, but it takes not the input <b>x</b> value
 itself, but the function value, which was calculated previously with
 the help of "Function" method.</para>
 
 <para><note>Some applications require as function value, as derivative value,
 so they can save the amount of calculations using this method to calculate derivative.</note></para>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.BipolarSigmoidFunction.Clone">
 <summary>
 Creates a new object that is a copy of the current instance.
 </summary>
 
 <returns>
 A new object that is a copy of this instance.
 </returns>
 
</member>
<member name="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.IActivationFunction">
 <summary>
 Activation function interface.
 </summary>
 
 <remarks>All activation functions, which are supposed to be used with
 neurons, which calculate their output as a function of weighted sum of
 their inputs, should implement this interfaces.
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.IActivationFunction.Function(System.Double)">
 <summary>
 Calculates function value.
 </summary>

 <param name="x">Function input value.</param>
 
 <returns>Function output value, <i>f(x)</i>.</returns>

 <remarks>The method calculates function value at point <paramref name="x"/>.</remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.IActivationFunction.Derivative(System.Double)">
 <summary>
 Calculates function derivative.
 </summary>
 
 <param name="x">Function input value.</param>
 
 <returns>Function derivative, <i>f'(x)</i>.</returns>
 
 <remarks>The method calculates function derivative at point <paramref name="x"/>.</remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.IActivationFunction.Derivative2(System.Double)">
 <summary>
 Calculates function derivative.
 </summary>
 
 <param name="y">Function output value - the value, which was obtained
 with the help of "Function" method.</param>
 
 <returns>Function derivative, <i>f'(x)</i>.</returns>
 
 <remarks><para>The method calculates the same derivative value as the
 <see cref="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.IActivationFunction.Derivative(System.Double)"/> method, but it takes not the input <b>x</b> value
 itself, but the function value, which was calculated previously with
 the help of "Function" method.</para>
 
 <para><note>Some applications require as function value, as derivative value,
 so they can save the amount of calculations using this method to calculate derivative.</note></para>
 </remarks>
 
</member>
<member name="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction">
 <summary>
 Sigmoid activation function.
 </summary>

 <remarks><para>The class represents sigmoid activation function with
 the next expression:
 <code lang="none">
                1
 f(x) = ------------------
        1 + exp(-alpha * x)

           alpha * exp(-alpha * x )
 f'(x) = ---------------------------- = alpha * f(x) * (1 - f(x))
           (1 + exp(-alpha * x))^2
 </code>
 </para>

 <para>Output range of the function: <b>[0, 1]</b>.</para>
 
 <para>Functions graph:</para>
 <img src="img/neuro/sigmoid.bmp" width="242" height="172" />
 </remarks>
 
</member>
<member name="P:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction.Alpha">
 <summary>
 Sigmoid's alpha value.
 </summary>
 
 <remarks><para>The value determines steepness of the function. Increasing value of
 this property changes sigmoid to look more like a threshold function. Decreasing
 value of this property makes sigmoid to be very smooth (slowly growing from its
 minimum value to its maximum value).</para>

 <para>Default value is set to <b>2</b>.</para>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction.#ctor">
 <summary>
 Initializes a new instance of the <see cref="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction"/> class.
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction.#ctor(System.Double)">
 <summary>
 Initializes a new instance of the <see cref="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction"/> class.
 </summary>
 
 <param name="alpha">Sigmoid's alpha value.</param>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction.Function(System.Double)">
 <summary>
 Calculates function value.
 </summary>

 <param name="x">Function input value.</param>
 
 <returns>Function output value, <i>f(x)</i>.</returns>

 <remarks>The method calculates function value at point <paramref name="x"/>.</remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction.Derivative(System.Double)">
 <summary>
 Calculates function derivative.
 </summary>
 
 <param name="x">Function input value.</param>
 
 <returns>Function derivative, <i>f'(x)</i>.</returns>
 
 <remarks>The method calculates function derivative at point <paramref name="x"/>.</remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction.Derivative2(System.Double)">
 <summary>
 Calculates function derivative.
 </summary>
 
 <param name="y">Function output value - the value, which was obtained
 with the help of "Function" method.</param>
 
 <returns>Function derivative, <i>f'(x)</i>.</returns>
 
 <remarks><para>The method calculates the same derivative value as the
 <see cref="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction.Derivative(System.Double)"/> method, but it takes not the input <b>x</b> value
 itself, but the function value, which was calculated previously with
 the help of "Function" method.</para>
 
 <para><note>Some applications require as function value, as derivative value,
 so they can save the amount of calculations using this method to calculate derivative.</note></para>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.SigmoidFunction.Clone">
 <summary>
 Creates a new object that is a copy of the current instance.
 </summary>
 
 <returns>
 A new object that is a copy of this instance.
 </returns>
 
</member>
<member name="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.ThresholdFunction">
 <summary>
 Threshold activation function.
 </summary>

 <remarks><para>The class represents threshold activation function with
 the next expression:
 <code lang="none">
 f(x) = 1, if x >= 0, otherwise 0
 </code>
 </para>
 
 <para>Output range of the function: <b>[0, 1]</b>.</para>
 
 <para>Functions graph:</para>
 <img src="img/neuro/threshold.bmp" width="242" height="172" />
 </remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.ThresholdFunction.#ctor">
 <summary>
 Initializes a new instance of the <see cref="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.ThresholdFunction"/> class.
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.ThresholdFunction.Function(System.Double)">
 <summary>
 Calculates function value.
 </summary>

 <param name="x">Function input value.</param>
 
 <returns>Function output value, <i>f(x)</i>.</returns>

 <remarks>The method calculates function value at point <paramref name="x"/>.</remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.ThresholdFunction.Derivative(System.Double)">
 <summary>
 Calculates function derivative (not supported).
 </summary>
 
 <param name="x">Input value.</param>
 
 <returns>Always returns 0.</returns>
 
 <remarks><para><note>The method is not supported, because it is not possible to
 calculate derivative of the function.</note></para></remarks>

</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.ThresholdFunction.Derivative2(System.Double)">
 <summary>
 Calculates function derivative (not supported).
 </summary>
 
 <param name="y">Input value.</param>
 
 <returns>Always returns 0.</returns>
 
 <remarks><para><note>The method is not supported, because it is not possible to
 calculate derivative of the function.</note></para></remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.ThresholdFunction.Clone">
 <summary>
 Creates a new object that is a copy of the current instance.
 </summary>
 
 <returns>
 A new object that is a copy of this instance.
 </returns>
 
</member>
<member name="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.IFuncs.Sigmoid">
 <summary>
 https://github.com/trentsartain/Neural-Network/blob/master/NeuralNetwork/NeuralNetwork/Network/Sigmoid.cs
 </summary>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.NeuralNetwork.Synapse">
 <summary>
 （神经元的）突触 a connection between two nerve cells
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.NeuralNetwork.Synapse.Weight">
 <summary>
 两个神经元之间的连接强度
 </summary>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Serials.PeriodAnalysis.PeriodAnalysis.Analysis(System.Collections.Generic.IEnumerable{Microsoft.VisualBasic.DataMining.Serials.PeriodAnalysis.SerialsVarialble},System.String,System.UInt32)">
 <summary>
 
 </summary>
 <param name="UniqueId"></param>
 <param name="WindowSize"></param>
 <returns></returns>
 <remarks></remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Serials.PeriodAnalysis.PeriodAnalysis.Analysis(Microsoft.VisualBasic.DataMining.Serials.PeriodAnalysis.SerialsVarialble,System.UInt32)">
 <summary>
 返回的数据是周期变化数据，故而假若需要计算频率变化的话，还需要求倒数
 </summary>
 <param name="SerialsData"></param>
 <param name="WindowSize"></param>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Serials.PeriodAnalysis.PeriodAnalysis.LoadDataFromCsv(System.String)">
 <summary>
 
 </summary>
 <param name="path"></param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.QLearning.Action">
 <summary>
 One specific environment state have some possible actions,
 but there is just one best action on the current environment state based on the accumulate q-values
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.Action.EnvirState">
 <summary>
 The environment variables state as inputs for the machine.
 </summary>
 <returns></returns>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.Action.Qvalues">
 <summary>
 Actions for the current state.
 </summary>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.Action.ToString">
 <summary>
 Environment -> actions' Q-values
 </summary>
 <returns></returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.QLearning.DataModel.QModel">
 <summary>
 Data model of the <see cref="T:Microsoft.VisualBasic.DataMining.QLearning.QTable`1"/>, you can using this object to stores the trained QL_AI into a file.
 </summary>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.QLearning.DataModel.IndexCurve">
 <summary>
 属性是时间
 </summary>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.QLearning.QState`1">
 <summary>
 
 </summary>
 <typeparam name="T">Status object</typeparam>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QState`1.State">
 <summary>
 假若操作不会涉及到数据修改，请使用这个属性来减少性能的损失，<see cref="P:Microsoft.VisualBasic.DataMining.QLearning.QState`1.Current"/>属性返回的值和本属性是一样的，
 只不过<see cref="P:Microsoft.VisualBasic.DataMining.QLearning.QState`1.Current"/>属性是从<see cref="M:System.ICloneable.Clone"/>方法得到的数据，所以性能方面会有损失
 </summary>
 <returns></returns>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QState`1.Current">
 <summary>
 map before the action is taken, clone object: <see cref="M:System.ICloneable.Clone"/>
 </summary>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QState`1.GetNextState(System.Int32)">
 <summary>
 Gets the <see cref="P:Microsoft.VisualBasic.DataMining.QLearning.QState`1.Current"/> states.
 Returns the map state which results from an initial map state after an
 action is applied. In case the action is invalid, the returned map is the
 same as the initial one (no move). </summary>
 <param name="action"> taken by the avatar ('@') </param>
 <returns> resulting map after the action is taken </returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.QLearning.QLearning`1">
 <summary>
 Q Learning sample class <br/>
 <b>The goal of this code sample is for the character @ to reach the goal area G</b> <br/>
 compile using "javac QLearning.java" <br/>
 test using "java QLearning" <br/>
 
 @author A.Liapis (Original author), A. Hartzen (2013 modifications) 
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QLearning`1.ActionRange">
 <summary>
 The size of the <see cref="T:Microsoft.VisualBasic.DataMining.QLearning.QTable`1"/>
 </summary>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QLearning`1.__run(System.Int32)">
 <summary>
 Takes a action for the agent.
 </summary>
 <param name="i">Iteration counts.</param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QLearning`1.__reset(System.Int32)">
 <summary>
 If the <see cref="P:Microsoft.VisualBasic.DataMining.QLearning.QLearning`1.GoalReached"/> then reset and continute learning.
 </summary>
 <param name="i">机器学习的当前的迭代次数</param>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QLearning`1.GoalRewards">
 <summary>
 目标达成所得到的奖励
 </summary>
 <returns></returns>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QLearning`1.GoalPenalty">
 <summary>
 目标没有达成的罚分
 </summary>
 <returns></returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QLearning`1.__finishLearn">
 <summary>
 You can save you q table by overrides at here.
 </summary>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.QLearning.QTable`1">
 <summary>
 The heart of the Q-learning algorithm, the QTable contains the table
 which maps states, actions and their Q values. This class has elaborate
 documentation, and should be the focus of the students' body of work
 for the purposes of this tutorial.

 @author A.Liapis (Original author), A. Hartzen (2013 modifications); xie.guigang@gcmodeller.org (2016 modifications)
 </summary>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.__randomGenerator">
 <summary>
 for creating random numbers
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.Table">
 <summary>
 the table variable stores the Q-table, where the state is saved
 directly as the actual map. Each map state has an array of Q values
 for all the actions available for that state.
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.ActionRange">
 <summary>
 the actionRange variable determines the number of actions available
 at any map state, and therefore the number of Q values in each entry
 of the Q-table.
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.ExplorationChance">
 <summary>
 for e-greedy Q-learning, when taking an action a random number is
 checked against the explorationChance variable: if the number is
 below the explorationChance, then exploration takes place picking
 an action at random. Note that the explorationChance is not a final
 because it is customary that the exploration chance changes as the
 training goes on.
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.GammaValue">
 <summary>
 the discount factor is saved as the gammaValue variable. The
 discount factor determines the importance of future rewards.
 If the gammaValue is 0 then the AI will only consider immediate
 rewards, while with a gammaValue near 1 (but below 1) the AI will
 try to maximize the long-term reward even if it is many moves away.
 </summary>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.LearningRate">
 <summary>
 the learningRate determines how new information affects accumulated
 information from previous instances. If the learningRate is 1, then
 the new information completely overrides any previous information.
 Note that the learningRate is not a final because it is
 customary that the learningRate changes as the
 training goes on.
 </summary>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.QLearning.QTable`1._prevState">
 <summary>
 Since in Q-learning the updates to the Q values are made ONE STEP
 LATE, the state of the world when the action resulting in the reward
 was made must be stored.
 </summary>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.QLearning.QTable`1._prevAction">
 <summary>
 Since in Q-learning the updates to the Q values are made ONE STEP
 LATE, the index of the action which resulted in the reward must be
 stored.
 </summary>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.#ctor(System.Int32)">
 <summary>
 Q table constructor, initiates variables. </summary>
 <param name="actionRange"> number of actions available at any map state </param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.NextAction(`0)">
 <summary>
 For this example, the getNextAction function uses an e-greedy
 approach, having exploration happen if the exploration chance
 is rolled.
 ( **** 请注意，这个函数所返回的值为最佳选择的Index编号，所以可能还需要进行一些转换 **** )
 </summary>
 <param name="map"> current map (state) </param>
 <returns> the action to be taken by the calling program </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.__getBestAction(`0)">
 <summary>
 The getBestAction function uses a greedy approach for finding
 the best action to take. Note that if all Q values for the current
 state are equal (such as all 0 if the state has never been visited
 before), then getBestAction will always choose the same action.
 If such an action is invalid, this may lead to a deadlock as the
 map state never changes: for situations like these, exploration
 can get the algorithm out of this deadlock.
 </summary>
 <param name="map"> current map (state) </param>
 <returns> the action with the highest Q value </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.__explore">
 <summary>
 The explore function is called for e-greedy algorithms.
 It can choose an action at random from all available,
 or can put more weight towards actions that have not been taken
 as often as the others (most unknown).
 </summary>
 <returns> index of action to take </returns>
 <remarks>在这里得到可能的下一步的动作的在动作列表里面编号值， Index</remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.UpdateQvalue(System.Int32,`0)">
 <summary>
 The updateQvalue is the heart of the Q-learning algorithm. Based on
 the reward gained by taking the action prevAction while being in the
 state prevState, the updateQvalue must update the Q value of that
 {prevState, prevAction} entry in the Q table. In order to do that,
 the Q value of the best action of the current map state must also
 be calculated.
 </summary>
 <param name="reward"> at the current map state </param>
 <param name="map"> current map state (for finding the best action of the
 current map state) </param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.__getMapString(`0)">
 <summary>
 This helper function is used for entering the map state into the
 HashMap </summary>
 <param name="map"> </param>
 <returns> String used as a key for the HashMap </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.__getActionsQValues(`0)">
 <summary>
 The getActionsQValues function returns an array of Q values for
 all the actions available at any state. Note that if the current
 map state does not already exist in the Q table (never visited
 before), then it is initiated with Q values of 0 for all of the
 available actions.
 </summary>
 <param name="map"> current map (state) </param>
 <returns> an array of Q values for all the actions available at any state </returns>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.QLearning.QTable`1.GetValues(`0)">
 <summary>
 Helper function to find the Q-values of a given map state.
 </summary>
 <param name="map"> current map (state) </param>
 <returns> the Q-values stored of the Qtable entry of the map state, otherwise null if it is not found </returns>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.Statistics">
 <summary>
 Set of statistics functions.
 </summary>
 
 <remarks>The class represents collection of simple functions used
 in statistics.</remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Statistics.Mean(System.Int32[])">
 <summary>
 Calculate mean value.
 </summary>
 
 <param name="values">Histogram array.</param>
 
 <returns>Returns mean value.</returns>
 
 <remarks><para>The input array is treated as histogram, i.e. its
 indexes are treated as values of stochastic function, but
 array values are treated as "probabilities" (total amount of
 hits).</para>
 
 <para>Sample usage:</para>
 <code>
 // create histogram array
 int[] histogram = new int[] { 1, 1, 2, 3, 6, 8, 11, 12, 7, 3 };
 // calculate mean value
 double mean = Statistics.Mean( histogram );
 // output it (5.759)
 Console.WriteLine( "mean = " + mean.ToString( "F3" ) );
 </code>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Statistics.StdDev(System.Int32[])">
 <summary>
 Calculate standard deviation.
 </summary>
 <param name="values">Histogram array.</param>
 <returns>Returns value of standard deviation.</returns>
 <remarks>
 The input array is treated as histogram, i.e. its
 indexes are treated as values of stochastic function, but
 array values are treated as "probabilities" (total amount of
 hits).
 
 Sample usage:
 
 ```vbnet
 ' create histogram array
 Dim histogram As Integer() = New Integer() { 1, 1, 2, 3, 6, 8, 11, 12, 7, 3 }
 ' calculate standard deviation value
 Dim stdDev = Statistics.StdDev( histogram )
 '' output it (1.999)
 Console.WriteLine( "std.dev. = " &amp; stdDev.ToString( "F3" ) )
 ```
 </remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Statistics.StdDev(System.Int32[],System.Double)">
 <summary>
 Calculate standard deviation.
 </summary>
 
 <param name="values">Histogram array.</param>
 <param name="mean">Mean value of the histogram.</param>
 
 <returns>Returns value of standard deviation.</returns>
 
 <remarks><para>The input array is treated as histogram, i.e. its
 indexes are treated as values of stochastic function, but
 array values are treated as "probabilities" (total amount of
 hits).</para>
 
 <para>The method is an equevalent to the <see cref="M:Microsoft.VisualBasic.DataMining.Statistics.StdDev(System.Int32[])"/> method,
 but it relieas on the passed mean value, which is previously calculated
 using <see cref="M:Microsoft.VisualBasic.DataMining.Statistics.Mean(System.Int32[])"/> method.</para>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Statistics.Median(System.Int32[])">
 <summary>
 Calculate median value.
 </summary>
 
 <param name="values">Histogram array.</param>
 
 <returns>Returns value of median.</returns>
 
 <remarks>
 <para>The input array is treated as histogram, i.e. its
 indexes are treated as values of stochastic function, but
 array values are treated as "probabilities" (total amount of
 hits).</para>
 
 <para><note>The median value is calculated accumulating histogram's
 values starting from the <b>left</b> point until the sum reaches 50% of
 histogram's sum.</note></para>
 
 <para>Sample usage:</para>
 <code>
 // create histogram array
 int[] histogram = new int[] { 1, 1, 2, 3, 6, 8, 11, 12, 7, 3 };
 // calculate median value
 int median = Statistics.Median( histogram );
 // output it (6)
 Console.WriteLine( "median = " + median );
 </code>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Statistics.GetRange(System.Int32[],System.Double)">
 <summary>
 Get range around median containing specified percentage of values.
 </summary>
 
 <param name="values">Histogram array.</param>
 <param name="percent">Values percentage around median.</param>
 
 <returns>Returns the range which containes specifies percentage
 of values.</returns>
 
 <remarks>
 <para>The input array is treated as histogram, i.e. its
 indexes are treated as values of stochastic function, but
 array values are treated as "probabilities" (total amount of
 hits).</para>
 
 <para>The method calculates range of stochastic variable, which summary probability
 comprises the specified percentage of histogram's hits.</para>
 
 <para>Sample usage:</para>
 <code>
 // create histogram array
 int[] histogram = new int[] { 1, 1, 2, 3, 6, 8, 11, 12, 7, 3 };
 // get 75% range around median
 IntRange range = Statistics.GetRange( histogram, 0.75 );
 // output it ([4, 8])
 Console.WriteLine( "range = [" + range.Min + ", " + range.Max + "]" );
 </code>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Statistics.Entropy(System.Int32[])">
 <summary>
 Calculate entropy value.
 </summary>
 
 <param name="values">Histogram array.</param>
 
 <returns>Returns entropy value of the specified histagram array.</returns>
 
 <remarks><para>The input array is treated as histogram, i.e. its
 indexes are treated as values of stochastic function, but
 array values are treated as "probabilities" (total amount of
 hits).</para>
 
 <para>Sample usage:</para>
 <code>
 // create histogram array with 2 values of equal probabilities
 int[] histogram1 = new int[2] { 3, 3 };
 // calculate entropy
 double entropy1 = Statistics.Entropy( histogram1 );
 // output it (1.000)
 Console.WriteLine( "entropy1 = " + entropy1.ToString( "F3" ) );
 
 // create histogram array with 4 values of equal probabilities
 int[] histogram2 = new int[4] { 1, 1, 1, 1 };
 // calculate entropy
 double entropy2 = Statistics.Entropy( histogram2 );
 // output it (2.000)
 Console.WriteLine( "entropy2 = " + entropy2.ToString( "F3" ) );
 
 // create histogram array with 4 values of different probabilities
 int[] histogram3 = new int[4] { 1, 2, 3, 4 };
 // calculate entropy
 double entropy3 = Statistics.Entropy( histogram3 );
 // output it (1.846)
 Console.WriteLine( "entropy3 = " + entropy3.ToString( "F3" ) );
 </code>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Statistics.Mode(System.Int32[])">
 <summary>
 Calculate mode value.
 </summary>
 
 <param name="values">Histogram array.</param>
 
 <returns>Returns mode value of the histogram array.</returns>
 
 <remarks>
 <para>The input array is treated as histogram, i.e. its
 indexes are treated as values of stochastic function, but
 array values are treated as "probabilities" (total amount of
 hits).</para>
 
 <para><note>Returns the minimum mode value if the specified histogram is multimodal.</note></para>

 <para>Sample usage:</para>
 <code>
 // create array
 int[] values = new int[] { 1, 1, 2, 3, 6, 8, 11, 12, 7, 3 };
 // calculate mode value
 int mode = Statistics.Mode( values );
 // output it (7)
 Console.WriteLine( "mode = " + mode );
 </code>
 </remarks>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.SVD.SVDecomposition(System.Double[0:,0:],System.Double[]@,System.Double[0:,0:]@)">
 <summary>
 Singular Value Decomposition
 </summary>
 <param name="a">Number of rows in A must be greater or equal to number of columns</param>
 <param name="w"></param>
 <param name="v"></param>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.WaveletTransform">
 <summary>
 小波变换工具
 </summary>
 <remarks>
 
 The first DWT was invented by the Hungarian mathematician Alfréd Haar. For an input represented by a 
 list of 2n numbers, the Haar wavelet transform may be considered to simply pair up input values, 
 storing the difference and passing the sum. This process is repeated recursively, pairing up the sums 
 to provide the next scale: finally resulting in 2n-1 differences and one final sum.
 
 Suppose you are given N values
 
 x = (x1, x2, … xN)
 
 where N is even.(X向量的元素的个数必须是偶数)
 
 We take pair-wise average of numbers
 
 sk = (x2k + x2k+1)/2 for k=0, …, N/2 -1
 
 For example,
 
 x = (6, 12, 15, 15, 14, 12, 120, 116) -> s = (9, 15, 13, 118)
 
 We need second list of data d so that the original list x can be recovered from s and d.
 
 For dk (called directed distances), we have:
 
 dk = (x2k - x2k+1)/2 for k=0, …, N/2 -1
 
 The process is invertible since:
 
 sk + dk = (x2k + x2k+1)/2 + (x2k - x2k+1)/2 = x2k
 
 sk - dk = (x2k + x2k+1)/2 - (x2k - x2k+1)/2 = x2k+1
 
 
 So we map x = (x1, x2, … , xN) to (s | d) = (s1, … , sN/2 | d1, … , dN/2).
 
 Using our example values, we have:
 
 (6, 12, 15, 15, 14, 12, 120, 116) -> (9, 15, 13, 118 | -3, 0, 1, 2)
 
 This process is repeated recursively for s:
 
 (9, 15, 13, 118 | -3, 0, 1, 2) -> (12, 65.5 | -3, -52.5 | -3, 0, 1, 2)
 
 (12, 65.5 | -3, -52.5 | -3, 0, 1, 2) -> (38.75 | -26.75 | -3, -52.5 | -3, 0, 1, 2)
 
 So final result is:
 
 (38.75, -26.75, -3, -52.5, -3, 0, 1, 2)
 
 Why might people prefer the data in this form?
 
 We can identify large changes in the differences portion d of the transform.
 It is easier to quantize the data in this form.
 The transform concentrates the information (energy) in the signal in fewer values.
 And the obvious answer: fewer digits!!
 In case of images, we need 2D FWT. First, we perform 1D FWT for all rows, and next, for all columns. 
 For color Images, we deal with RGB components of color, and perform Haar Transform for each component 
 separately. Any component (R G B) has values from 0 to 255 to before transformation we scale this 
 values. For displaying image after transformation, we scale back transformed values.
 
 </remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.WaveletTransform.FWT(System.Double[]@)">
 <summary>
   Discrete Haar Wavelet Transform
 </summary>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.WaveletTransform.FWT(System.Double[0:,0:]@,System.Int32)">
 <summary>
   Discrete Haar Wavelet 2D Transform
 </summary>
 <param name="iterations">Iteration must be Integer from 1 to</param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.WaveletTransform.IWT(System.Double[]@)">
 <summary>
   Inverse Haar Wavelet Transform
 </summary>
 
</member>
<member name="M:Microsoft.VisualBasic.DataMining.WaveletTransform.IWT(System.Double[0:,0:]@,System.Int32)">
 <summary>
   Inverse Haar Wavelet 2D Transform
 </summary>
 <param name="iterations">Iteration must be Integer from 1 to</param>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.ValueMapping.ModalNumber(System.Int32[])">
 <summary>
 Gets the modal number of the ranking mapping data set.(求取众数)
 </summary>
 <param name="data">The ranked mapping encoding value.(经过Rank Mapping处理过后的编码值)</param>
 <returns></returns>
 <remarks>
 当不存在相同的分组元素数目的时候，会直接取第一个元素的值作为众数
 当存在相同的分组元素数目的时候，会取最大的元素值作为众数
 </remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.Kernel.BayesianBeliefNetwork.BeliefNode">
 <summary>
 贝叶斯信念网络中的一个节点
 </summary>
 <remarks></remarks>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.Kernel.BayesianBeliefNetwork.BeliefNode.Parents">
 <summary>
 本节点的父节点
 </summary>
 <remarks></remarks>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.Kernel.BayesianBeliefNetwork.BeliefNode.CP_Table">
 <summary>
 CP Table，用于把各节点和它的直接父节点相关联起来的一个概率表
 </summary>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.Kernel.BayesianBeliefNetwork.BeliefNetwork">
 <summary>
 贝叶斯信念网络
 </summary>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Kernel.BayesianBeliefNetwork.BeliefNetwork.SetNodes(System.Int32[])">
 <summary>
 
 </summary>
 <param name="Array">Array的元素个数必须与节点的数目相等</param>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Kernel.BayesianBeliefNetwork.BeliefNetwork.CreateFrom(System.String)">
 <summary>
 
 </summary>
 <param name="File">网络数据的文件路径</param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Kernel.BayesianBeliefNetwork.BElim.GetBelief(System.Int32[],System.Int32[])">
 <summary>
 计算条件概率: P(x|conditions)，对于计算对象x和计算条件condition二者的元素必须要错开。对于错开部分的空的元素请使用-1来填充
 </summary>
 <param name="x"></param>
 <param name="conditions"></param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="P:Microsoft.VisualBasic.DataMining.Kernel.Classifier.Neuron.OutputFunction">
 <summary>
 Weights, Entity, OutputValue
 </summary>
 <value></value>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Kernel.Classifier.Neuron.Entity.CastTo(Microsoft.VisualBasic.Data.csv.DocumentStream.RowObject)">
 <summary>
 
 </summary>
 <param name="row">第一个元素为分类，其余元素为属性</param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.Kernel.Classifier.Bayesian">
 <summary>
 朴素贝叶斯分类器
 </summary>
 <remarks></remarks>
</member>
<member name="F:Microsoft.VisualBasic.DataMining.Kernel.Classifier.Bayesian.Entities">
 <summary>
 原始的数据集合
 </summary>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Kernel.Classifier.Bayesian.P(Microsoft.VisualBasic.DataMining.ComponentModel.Entity,System.Int32)">
 <summary>
 P(X|Y=y)
 </summary>
 <param name="X"></param>
 <param name="Y"></param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.Kernel.Classifier.Bayesian.P(System.Int32[],System.Int32)">
 <summary>
 P(X|Y=y)
 </summary>
 <param name="X">Subject Condition</param>
 <param name="Y">Target Classify</param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.ComponentModel.EntityBase`1">
 <summary>

 </summary>
 <typeparam name="T">只允许数值类型</typeparam>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.ComponentModel.Entity">
 <summary>
 {Properties} -> Class
 </summary>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.ComponentModel.Entity.CastTo(Microsoft.VisualBasic.Data.csv.DocumentStream.RowObject)">
 <summary>

 </summary>
 <param name="row">第一个元素为分类，其余元素为属性</param>
 <returns></returns>
 <remarks></remarks>
</member>
<member name="T:Microsoft.VisualBasic.DataMining.ComponentModel.Vector">
 <summary>
 用于表示一个对象实体的属性值的一个向量
 </summary>
 <remarks></remarks>
</member>
<member name="M:Microsoft.VisualBasic.DataMining.ComponentModel.Vector.Randomize(System.UInt32,System.Double,System.Double)">
 <summary>
 生成一个指定长度的随机数序列
 </summary>
 <param name="Length"></param>
 <param name="Upper"></param>
 <param name="Lower"></param>
 <returns></returns>
</member>
</members>
</doc>
